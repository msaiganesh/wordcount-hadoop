WORDS PER LINE USECASE-TRACE
-----------------------------
TO FIND HOW MANY NUM OF WORDS ARE THRE PER EACH LINE THRU MAP REDUCE PRG
------------------------------------------------------------------------


root@ubuntu:/home/Gopal/MapReduce/DynamicWC# nano inputData.log
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# hadoop fs -mkdir /WordsPerLineInput
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# 
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# hadoop fs -put inputData.log /WordsPerLineInput
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# 

root@ubuntu:/home/Gopal/MapReduce/DynamicWC# hadoop jar WORDS_PER_LINE.jar com.gopal.mapred.WordsPerLine /WordsPerLineInput /WordsPerLineOutputPath
14/04/14 07:21:48 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
14/04/14 07:21:49 INFO input.FileInputFormat: Total input paths to process : 1
14/04/14 07:21:49 WARN snappy.LoadSnappy: Snappy native library is available
14/04/14 07:21:49 INFO util.NativeCodeLoader: Loaded the native-hadoop library
14/04/14 07:21:49 INFO snappy.LoadSnappy: Snappy native library loaded
14/04/14 07:21:50 INFO mapred.JobClient: Running job: job_201404140649_0003
14/04/14 07:21:51 INFO mapred.JobClient:  map 0% reduce 0%
14/04/14 07:22:02 INFO mapred.JobClient:  map 100% reduce 0%
14/04/14 07:22:11 INFO mapred.JobClient:  map 100% reduce 33%
14/04/14 07:22:13 INFO mapred.JobClient:  map 100% reduce 100%
14/04/14 07:22:15 INFO mapred.JobClient: Job complete: job_201404140649_0003
14/04/14 07:22:15 INFO mapred.JobClient: Counters: 26
14/04/14 07:22:15 INFO mapred.JobClient:   Job Counters 
14/04/14 07:22:15 INFO mapred.JobClient:     Launched reduce tasks=1
14/04/14 07:22:15 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=12615
14/04/14 07:22:15 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
14/04/14 07:22:15 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
14/04/14 07:22:15 INFO mapred.JobClient:     Launched map tasks=1
14/04/14 07:22:15 INFO mapred.JobClient:     Data-local map tasks=1
14/04/14 07:22:15 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=10718
14/04/14 07:22:15 INFO mapred.JobClient:   FileSystemCounters
14/04/14 07:22:15 INFO mapred.JobClient:     FILE_BYTES_READ=774
14/04/14 07:22:15 INFO mapred.JobClient:     HDFS_BYTES_READ=484
14/04/14 07:22:15 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=121034
14/04/14 07:22:15 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=52
14/04/14 07:22:15 INFO mapred.JobClient:   Map-Reduce Framework
14/04/14 07:22:15 INFO mapred.JobClient:     Map input records=6
14/04/14 07:22:15 INFO mapred.JobClient:     Reduce shuffle bytes=774
14/04/14 07:22:15 INFO mapred.JobClient:     Spilled Records=128
14/04/14 07:22:15 INFO mapred.JobClient:     Map output bytes=640
14/04/14 07:22:15 INFO mapred.JobClient:     CPU time spent (ms)=8160
14/04/14 07:22:15 INFO mapred.JobClient:     Total committed heap usage (bytes)=193134592
14/04/14 07:22:15 INFO mapred.JobClient:     Combine input records=0
14/04/14 07:22:15 INFO mapred.JobClient:     SPLIT_RAW_BYTES=118
14/04/14 07:22:15 INFO mapred.JobClient:     Reduce input records=64
14/04/14 07:22:15 INFO mapred.JobClient:     Reduce input groups=6
14/04/14 07:22:15 INFO mapred.JobClient:     Combine output records=0
14/04/14 07:22:15 INFO mapred.JobClient:     Physical memory (bytes) snapshot=339542016
14/04/14 07:22:15 INFO mapred.JobClient:     Reduce output records=6
14/04/14 07:22:15 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=890597376
14/04/14 07:22:15 INFO mapred.JobClient:     Map output records=64
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# 

INPUT DATA
------------

root@ubuntu:/home/Gopal/MapReduce/DynamicWC# hadoop fs -cat /WordsPerLineInput/inputData.log
Hadoop is one of the bigdata analytics tool
Bigdata is not only storage but also the processing related aspect
Apache Pig is a highlevel and abstract componet on top of Map Reduce
SQOOP is the component to intract with RDBMS to import and export data
HIVE is a warehouse kind of technology in Hadoop
HBase is the Hadoop's Database to read/write the data dynamically
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# 



root@ubuntu:/home/Gopal/MapReduce/DynamicWC# hadoop fs -ls /WordsPerLineOutputPath
Found 3 items
-rw-r--r--   1 root supergroup          0 2014-04-14 07:22 /WordsPerLineOutputPath/_SUCCESS
drwxr-xr-x   - root supergroup          0 2014-04-14 07:21 /WordsPerLineOutputPath/_logs
-rw-r--r--   1 root supergroup         52 2014-04-14 07:22 /WordsPerLineOutputPath/part-r-00000
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# 

GENERATED OUTPUT
----------------
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# hadoop fs -cat /WordsPerLineOutputPath/part-r-00000
line1	8
line2	11
line3	13
line4	13
line5	9
line6	10
root@ubuntu:/home/Gopal/MapReduce/DynamicWC# 



